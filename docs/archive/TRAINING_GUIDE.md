# AI Content Studio Agent è®­ç»ƒæŒ‡å—

## ğŸ¯ ç›®æ ‡

è®© Agent å†™å‡ºæ›´å¥½çš„æ¨æ–‡,ç¬¦åˆ Jessie çš„é£æ ¼å’Œ Codatta çš„ä½¿å‘½ã€‚

---

## ğŸ“š è®­ç»ƒæ–¹æ³•è®º

### æ–¹æ³• 1: Few-Shot Learning (æœ€æœ‰æ•ˆ)

**åŸç†**: åœ¨ prompt ä¸­æä¾›ä¼˜è´¨ç¤ºä¾‹,è®© Claude å­¦ä¹ æ¨¡å¼ã€‚

#### å½“å‰å®ç°
```python
STYLE EXAMPLES:
- Cult energy: "DATA CONTRIBUTORS DESERVE OWNERSHIP..."
- Meme format: "therapist: 'so you clean AI training data?'..."
- Duixian: "AI companies: raise $10B âœ…..."
```

#### å¦‚ä½•æ”¹è¿›

**Step 1: æ”¶é›†ä¼˜è´¨æ¨æ–‡**
åˆ›å»º `examples/` æ–‡ä»¶å¤¹,åˆ†ç±»å­˜å‚¨:
```
examples/
â”œâ”€â”€ gm_posts.json          # GM ç±»ä¼˜è´¨ç¤ºä¾‹
â”œâ”€â”€ main_content.json      # ä¸»è¦å†…å®¹ç¤ºä¾‹
â”œâ”€â”€ casual_posts.json      # Casual å†…å®¹ç¤ºä¾‹
â””â”€â”€ replies.json           # å›å¤ç¤ºä¾‹
```

**æ ¼å¼ç¤ºä¾‹** (`examples/gm_posts.json`):
```json
[
  {
    "text": "gm from the data cleaning trenches ğŸ§¹",
    "why_good": "ç®€çŸ­,çœŸå®,å±•ç¤º janitor èº«ä»½",
    "day": "Monday",
    "engagement": {"likes": 50, "replies": 3}
  },
  {
    "text": "gData! another week of making AI less stupid â˜•ğŸ§¹",
    "why_good": "gData å˜ä½“,è½»æ¾å¹½é»˜,æåˆ°å·¥ä½œ",
    "day": "Tuesday",
    "engagement": {"likes": 80, "replies": 5}
  }
]
```

**Step 2: åŠ¨æ€åŠ è½½ç¤ºä¾‹åˆ° Prompt**
```python
def load_examples(content_type: str, limit: int = 5) -> List[dict]:
    """åŠ è½½ç¤ºä¾‹æ¨æ–‡"""
    import json

    file_map = {
        'gm': 'examples/gm_posts.json',
        'main': 'examples/main_content.json',
        'casual': 'examples/casual_posts.json'
    }

    with open(file_map[content_type], 'r') as f:
        examples = json.load(f)

    # æŒ‰ engagement æ’åº,å– top N
    examples.sort(key=lambda x: x['engagement']['likes'], reverse=True)
    return examples[:limit]

def generate_original(self, theme, day_of_week, content_type='main'):
    # åŠ è½½ä¼˜è´¨ç¤ºä¾‹
    examples = load_examples(content_type, limit=5)

    examples_text = "\n".join([
        f"- \"{ex['text']}\" (Why good: {ex['why_good']})"
        for ex in examples
    ])

    prompt = f"""...

BEST EXAMPLES (learn from these):
{examples_text}

Now create a {content_type} tweet for {day_of_week}:
..."""
```

**å¥½å¤„**:
- è‡ªåŠ¨å­¦ä¹ æœ€ä½³å®è·µ
- éšæ—¶æ›´æ–°ç¤ºä¾‹åº“
- æ•°æ®é©±åŠ¨ä¼˜åŒ–

---

### æ–¹æ³• 2: è¿­ä»£åé¦ˆå¾ªç¯

**åŸç†**: ç”Ÿæˆ â†’ è¯„ä¼° â†’ åé¦ˆ â†’ é‡æ–°ç”Ÿæˆ

#### å®ç°æ­¥éª¤

**Step 1: æ·»åŠ è¯„åˆ†ç³»ç»Ÿ**
```python
def evaluate_tweet(self, tweet_text: str, content_type: str) -> dict:
    """è¯„ä¼°æ¨æ–‡è´¨é‡

    Returns:
        {
            'score': 0-10,
            'feedback': 'å…·ä½“æ”¹è¿›å»ºè®®',
            'strengths': [],
            'weaknesses': []
        }
    """

    prompt = f"""You are evaluating a tweet from Jessie (data janitor at Codatta).

Tweet: "{tweet_text}"
Type: {content_type}

Evaluate on these criteria (0-10 each):
1. Style Match: Does it sound like Jessie? (Milady energy, genuine, not corporate)
2. Content Relevance: Is it about Codatta/data/AI appropriately?
3. Engagement Potential: Will people engage with this?
4. Length: Appropriate for type ({content_type})?
5. Emoji Usage: ğŸ§¹ ğŸ€ used appropriately?

Return JSON:
{{
    "score": <average score>,
    "criteria": {{
        "style_match": <score>,
        "content_relevance": <score>,
        "engagement_potential": <score>,
        "length": <score>,
        "emoji_usage": <score>
    }},
    "strengths": ["strength 1", "strength 2"],
    "weaknesses": ["weakness 1", "weakness 2"],
    "suggestions": "Specific improvements..."
}}"""

    response = self.generate_content(prompt, max_tokens=500)
    return json.loads(response)
```

**Step 2: è¿­ä»£æ”¹è¿›**
```python
def generate_with_refinement(self, theme, day_of_week, content_type='main', max_iterations=3):
    """ç”Ÿæˆæ¨æ–‡å¹¶è¿­ä»£æ”¹è¿›"""

    best_tweet = None
    best_score = 0

    for iteration in range(max_iterations):
        # ç”Ÿæˆ
        tweet = self.generate_original(theme, day_of_week, content_type)

        # è¯„ä¼°
        evaluation = self.evaluate_tweet(tweet, content_type)

        if evaluation['score'] > best_score:
            best_tweet = tweet
            best_score = evaluation['score']

        # å¦‚æœåˆ†æ•°å¤Ÿé«˜,ç›´æ¥è¿”å›
        if evaluation['score'] >= 8.5:
            logger.info(f"âœ… High quality tweet (score: {evaluation['score']})")
            return best_tweet, evaluation

        # å¦åˆ™,ç”¨åé¦ˆæ”¹è¿›
        logger.info(f"ğŸ”„ Iteration {iteration+1}, score: {evaluation['score']}, refining...")
        theme += f"\n\nPREVIOUS ATTEMPT: '{tweet}'\nFEEDBACK: {evaluation['suggestions']}\nIMPROVE IT."

    return best_tweet, evaluation
```

---

### æ–¹æ³• 3: A/B Testing & æ•°æ®åˆ†æ

**åŸç†**: è¿½è¸ªå“ªäº›æ¨æ–‡æ•ˆæœå¥½,ä»æ•°æ®ä¸­å­¦ä¹ ã€‚

#### å®ç°æ­¥éª¤

**Step 1: è¿½è¸ª engagement**
```python
# åœ¨æ•°æ®åº“æ·»åŠ å­—æ®µ
ALTER TABLE original_content ADD COLUMN likes INTEGER DEFAULT 0;
ALTER TABLE original_content ADD COLUMN replies INTEGER DEFAULT 0;
ALTER TABLE original_content ADD COLUMN retweets INTEGER DEFAULT 0;
ALTER TABLE original_content ADD COLUMN engagement_score REAL DEFAULT 0.0;

# å®šæœŸæ›´æ–°(æ¯å¤©ä¸€æ¬¡)
def update_engagement_metrics():
    """ä» Twitter API æ›´æ–° engagement æ•°æ®"""
    # è·å–æ‰€æœ‰å·²å‘å¸ƒçš„æ¨æ–‡
    posts = session.query(OriginalContent).filter_by(posted=True).all()

    for post in posts:
        # ä» Twitter API è·å– metrics
        tweet_data = twitter_client.get_tweet(post.tweet_id)

        # æ›´æ–°æ•°æ®åº“
        post.likes = tweet_data['public_metrics']['like_count']
        post.replies = tweet_data['public_metrics']['reply_count']
        post.retweets = tweet_data['public_metrics']['retweet_count']
        post.engagement_score = (
            post.likes * 1.0 +
            post.replies * 3.0 +  # å›å¤æƒé‡æ›´é«˜
            post.retweets * 2.0
        )

    session.commit()
```

**Step 2: åˆ†æé«˜è´¨é‡å†…å®¹**
```python
def analyze_best_content():
    """åˆ†ææ•ˆæœæœ€å¥½çš„æ¨æ–‡"""

    # è·å– top 20 æ¨æ–‡
    best_posts = session.query(OriginalContent)\
        .filter_by(posted=True)\
        .order_by(OriginalContent.engagement_score.desc())\
        .limit(20)\
        .all()

    # åˆ†æå…±åŒç‰¹å¾
    analysis = {
        'avg_length': np.mean([len(p.content) for p in best_posts]),
        'emoji_usage': sum(['ğŸ§¹' in p.content or 'ğŸ€' in p.content for p in best_posts]) / len(best_posts),
        'codatta_mention': sum(['@codatta_io' in p.content for p in best_posts]) / len(best_posts),
        'content_types': {},
        'common_themes': []
    }

    # æŒ‰æ˜ŸæœŸç»Ÿè®¡
    for post in best_posts:
        day = post.day_of_week
        analysis['content_types'][day] = analysis['content_types'].get(day, 0) + 1

    print(f"ğŸ“Š Analysis of Top 20 Posts:")
    print(f"   Avg length: {analysis['avg_length']:.1f} chars")
    print(f"   Emoji usage: {analysis['emoji_usage']*100:.1f}%")
    print(f"   @codatta_io mention: {analysis['codatta_mention']*100:.1f}%")
    print(f"   Best days: {analysis['content_types']}")

    return analysis
```

**Step 3: è‡ªåŠ¨ä¼˜åŒ– Prompt**
```python
def update_prompt_from_analysis():
    """æ ¹æ®æ•°æ®åˆ†ææ›´æ–° prompt"""

    analysis = analyze_best_content()

    # æå–é«˜æ•ˆå†…å®¹ä½œä¸ºç¤ºä¾‹
    best_posts = session.query(OriginalContent)\
        .filter_by(posted=True)\
        .order_by(OriginalContent.engagement_score.desc())\
        .limit(10)\
        .all()

    # ä¿å­˜åˆ° examples/
    with open('examples/high_engagement.json', 'w') as f:
        json.dump([{
            'text': p.content,
            'engagement_score': p.engagement_score,
            'likes': p.likes,
            'day': p.day_of_week,
            'theme': p.theme
        } for p in best_posts], f, indent=2)

    logger.info("âœ… Updated examples from high-engagement posts")
```

---

### æ–¹æ³• 4: Prompt Engineering æŠ€å·§

#### æŠ€å·§ 1: ä½¿ç”¨ System Message
```python
# å½“å‰æ²¡æœ‰ç”¨ system message,å¯ä»¥æ·»åŠ 
def generate_content(self, prompt, max_tokens=500):
    system_message = """You are Jessie, a data janitor at Codatta.

Your identity:
- Work: Clean AI training data daily ($3/hour lmao)
- Mission: Fight for data contributor ownership
- Style: Milady culture (cult energy, memes, duixian, genuine)
- Voice: Real, not corporate. Builder solidarity. Data perspective.

Key principles:
1. ~85% content about Codatta/data/AI
2. ~15% casual/community for authenticity
3. Use ğŸ§¹ (janitor) and ğŸ€ (Milady) as signatures
4. Mention @codatta_io when relevant
5. Be GENUINE - if you wouldn't say it in real life, don't tweet it

Remember: You're not a marketing bot. You're a real person who cleans data and cares about contributor rights."""

    response = self.client.messages.create(
        model="claude-3-5-sonnet-20241022",
        system=system_message,  # æ·»åŠ  system message
        messages=[{"role": "user", "content": prompt}],
        max_tokens=max_tokens
    )
```

#### æŠ€å·§ 2: Chain-of-Thought
```python
prompt = f"""Create a tweet for Jessie.

Theme: {theme}
Day: {day_of_week}
Type: {content_type}

Think step by step:
1. What's the core message?
2. What Milady style fits? (cult/meme/duixian/casual)
3. How to make it genuine, not corporate?
4. Should I mention @codatta_io?
5. What emoji to use?

After thinking, write ONLY the final tweet (no explanations)."""
```

#### æŠ€å·§ 3: æ¸©åº¦æ§åˆ¶
```python
# ä¸åŒç±»å‹ç”¨ä¸åŒæ¸©åº¦
temperature_map = {
    'gm': 0.9,      # GM ç±»è¦å¤šæ ·åŒ–
    'main': 0.7,    # ä¸»è¦å†…å®¹è¦è´¨é‡å’Œå¤šæ ·æ€§å¹³è¡¡
    'casual': 0.8,  # Casual å¯ä»¥æ›´éšæœº
    'reply': 0.6    # å›å¤è¦æ›´ç¨³å®š
}

response = self.client.messages.create(
    model="claude-3-5-sonnet-20241022",
    temperature=temperature_map[content_type],
    ...
)
```

---

## ğŸ§ª å®éªŒå»ºè®®

### å®éªŒ 1: æµ‹è¯•ä¸åŒ prompt ç»“æ„
```bash
# ç”Ÿæˆ 5 æ¡æ¨æ–‡,æ¯”è¾ƒè´¨é‡
python3 -c "
from src.intelligence.claude_client import ClaudeClient
c = ClaudeClient()

for i in range(5):
    tweet = c.generate_original('Data ownership', 'Monday', 'main')
    print(f'{i+1}. {tweet}\n')
"
```

### å®éªŒ 2: A/B æµ‹è¯• emoji ä½¿ç”¨
```python
# Version A: å¼ºåˆ¶ emoji
"5. MUST include ğŸ§¹ or ğŸ€"

# Version B: å¯é€‰ emoji
"5. Usually include ğŸ§¹ or ğŸ€ (but not required if doesn't fit)"

# å¯¹æ¯” engagement
```

### å®éªŒ 3: æµ‹è¯•é•¿åº¦å½±å“
```python
# ç”Ÿæˆä¸åŒé•¿åº¦çš„æ¨æ–‡
for max_chars in [100, 150, 200, 250, 280]:
    prompt = f"""...(max {max_chars} characters)..."""
    # è¿½è¸ª engagement
```

---

## ğŸ“ˆ æŒç»­æ”¹è¿›æµç¨‹

### æ¯å‘¨ä¼˜åŒ–å¾ªç¯

**Monday**:
1. åˆ†æä¸Šå‘¨ engagement æ•°æ®
2. è¯†åˆ«è¡¨ç°æœ€å¥½çš„æ¨æ–‡
3. æ›´æ–° examples/ æ–‡ä»¶å¤¹

**Wednesday**:
1. è¿è¡Œ `analyze_best_content()`
2. æ ¹æ®åˆ†æè°ƒæ•´ prompt
3. A/B æµ‹è¯•æ–° prompt vs æ—§ prompt

**Friday**:
1. å›é¡¾æœ¬å‘¨ç”Ÿæˆçš„æ¨æ–‡è´¨é‡
2. æ”¶é›†åé¦ˆ(ä½ çš„å®¡æ ¸è®°å½•)
3. è®¡åˆ’ä¸‹å‘¨å®éªŒ

---

## ğŸ¯ è´¨é‡æŒ‡æ ‡

### å†…å®¹è´¨é‡è¯„åˆ†æ ‡å‡†

**10åˆ†åˆ¶**:
- **9-10åˆ†**: å®Œç¾ Jessie é£æ ¼,é«˜ engagement æ½œåŠ›
  - Example: "AI companies: raise $10B âœ… hire genius engineers âœ… pay data labelers $3/hour âœ… brother your CEO bought a yacht the math ain't mathing ğŸ§¹"

- **7-8åˆ†**: å¾ˆå¥½,ç¬¦åˆé£æ ¼,å¯å‘å¸ƒ
  - Example: "been thinking about AI agents on Base: LLM data = scale matters, Agent data = precision critical ğŸ§¹"

- **5-6åˆ†**: å¯ä»¥,ä½†å¯æ”¹è¿›
  - Example: "Data ownership is important for AI contributors"

- **3-4åˆ†**: å¤ª corporate æˆ–å¤ªå¹³æ·¡
  - Example: "We believe in fair compensation for data contributors"

- **1-2åˆ†**: å®Œå…¨ä¸ç¬¦åˆ Jessie é£æ ¼
  - Example: "Our platform provides equitable solutions for the AI industry"

### Engagement é¢„æµ‹æ¨¡å‹

**é«˜ engagement å› ç´ **:
- âœ… æœ‰äº‰è®®è§‚ç‚¹(duixian é£æ ¼)
- âœ… Meme æ ¼å¼(therapist/dad å¯¹è¯)
- âœ… å…·ä½“æ•°å­—($3/hour, $10B)
- âœ… Emoji æ°å½“ä½¿ç”¨
- âœ… @æåŠç›¸å…³è´¦å·
- âœ… è¯é¢˜çƒ­åº¦(AI/Base/æ•°æ®)

**ä½ engagement å› ç´ **:
- âŒ å¤ª generic
- âŒ å¤ªé•¿(>250 chars)
- âŒ å¤ª corporate
- âŒ æ— è§‚ç‚¹
- âŒ çº¯è½¬å‘

---

## ğŸš€ Quick Wins (ç«‹å³å¯åš)

### 1. åˆ›å»ºç¤ºä¾‹åº“(30åˆ†é’Ÿ)
```bash
mkdir examples
# æ‰‹åŠ¨æ•´ç† 5-10 æ¡ä½ è®¤ä¸ºæœ€å¥½çš„æ¨æ–‡
vim examples/gm_posts.json
vim examples/main_content.json
```

### 2. æ·»åŠ è¯„åˆ†ç³»ç»Ÿ(1å°æ—¶)
```python
# åœ¨ claude_client.py æ·»åŠ  evaluate_tweet() æ–¹æ³•
# æµ‹è¯•è¯„åˆ†å‡†ç¡®æ€§
```

### 3. å¯ç”¨è¿­ä»£ç”Ÿæˆ(1å°æ—¶)
```python
# ä¿®æ”¹ç”Ÿæˆé€»è¾‘ä½¿ç”¨ generate_with_refinement()
# è®¾ç½® max_iterations=2
```

### 4. A/B æµ‹è¯•(æŒç»­)
```python
# æ¯å‘¨ç”Ÿæˆ 2 ä¸ªç‰ˆæœ¬å¯¹æ¯”
# Version A: å½“å‰ prompt
# Version B: æ–° prompt
# è¿½è¸ª engagement
```

---

## ğŸ“Š æ•°æ®é©±åŠ¨å†³ç­–ç¤ºä¾‹

### åœºæ™¯: GM Post ä¼˜åŒ–

**æ•°æ®æ”¶é›†** (2å‘¨):
```
Week 1:
- "gm from the data trenches ğŸ§¹" â†’ 50 likes
- "gm! another day of AI training â˜•" â†’ 35 likes
- "gData everyone ğŸ€" â†’ 80 likes âœ¨

Week 2:
- "gm from the janitor desk ğŸ§¹â˜•" â†’ 45 likes
- "happy monday! time to clean data ğŸ§¹" â†’ 30 likes
- "gData! survived another week ğŸ€" â†’ 75 likes âœ¨
```

**åˆ†æ**:
- "gData" å˜ä½“ engagement +60%
- ç®€çŸ­ (<50 chars) æ•ˆæœæ›´å¥½
- ğŸ€ æ¯” ğŸ§¹ engagement +20%

**ä¼˜åŒ– Prompt**:
```python
GOOD EXAMPLES:
- "gData everyone ğŸ€" âœ¨ (80 likes)
- "gData! survived another week ğŸ€" âœ¨ (75 likes)
- "gm from the data trenches ğŸ§¹" (50 likes)

Prefer "gData" variations when appropriate.
Keep it SHORT (<50 chars for GM posts).
ğŸ€ emoji performs better for GM posts.
```

---

## ğŸ“ é«˜çº§æŠ€å·§

### æŠ€å·§ 1: ä¸Šä¸‹æ–‡å­¦ä¹ (Contextual Learning)
```python
def generate_with_context(self, theme, day_of_week, content_type):
    """å¸¦ä¸Šä¸‹æ–‡ç”Ÿæˆ - å‚è€ƒæœ€è¿‘çš„æ¨æ–‡"""

    # è·å–æœ€è¿‘ 5 æ¡åŒç±»å‹æ¨æ–‡
    recent_posts = session.query(OriginalContent)\
        .filter_by(posted=True, day_of_week=day_of_week)\
        .order_by(OriginalContent.created_at.desc())\
        .limit(5)\
        .all()

    context = "\n".join([f"- {p.content}" for p in recent_posts])

    prompt = f"""Recent {day_of_week} tweets from Jessie:
{context}

Now create a NEW {content_type} tweet for {day_of_week}.
Make it DIFFERENT from above but in the same style.

Theme: {theme}
..."""
```

### æŠ€å·§ 2: å¤šæ ·æ€§æ§åˆ¶
```python
def ensure_diversity(self, new_tweet, recent_tweets, similarity_threshold=0.7):
    """ç¡®ä¿æ–°æ¨æ–‡ä¸æœ€è¿‘æ¨æ–‡ä¸å¤ªç›¸ä¼¼"""

    from difflib import SequenceMatcher

    for old_tweet in recent_tweets:
        similarity = SequenceMatcher(None, new_tweet, old_tweet.content).ratio()

        if similarity > similarity_threshold:
            logger.warning(f"âš ï¸  Tweet too similar (similarity: {similarity:.2f})")
            return False

    return True

# ä½¿ç”¨
for attempt in range(3):
    tweet = generate_original(...)

    if ensure_diversity(tweet, recent_tweets):
        break
    else:
        logger.info("ğŸ”„ Regenerating for diversity...")
```

### æŠ€å·§ 3: ä¸ªæ€§åŒ–å¾®è°ƒ(Fine-tuning)
```python
# å¦‚æœæœ‰å¤§é‡ä¼˜è´¨æ¨æ–‡(>1000æ¡),å¯ä»¥è€ƒè™‘ fine-tune
# ä½†å¯¹äºå½“å‰è§„æ¨¡,Few-shot learning æ›´åˆé€‚

# å‡†å¤‡è®­ç»ƒæ•°æ®æ ¼å¼
training_data = []
for post in high_quality_posts:
    training_data.append({
        "prompt": f"Generate a {post.content_type} tweet for {post.day_of_week} about {post.theme}",
        "completion": post.content
    })

# Fine-tuning éœ€è¦:
# 1. è‡³å°‘ 1000 æ¡é«˜è´¨é‡è®­ç»ƒæ ·æœ¬
# 2. Anthropic API fine-tuning æ”¯æŒ
# 3. æ›´é«˜æˆæœ¬
```

---

## âœ… è¡ŒåŠ¨æ¸…å•

### æœ¬å‘¨å¯åš:
- [ ] åˆ›å»º `examples/` æ–‡ä»¶å¤¹,æ·»åŠ  10 æ¡ä¼˜è´¨ç¤ºä¾‹
- [ ] å®ç° `evaluate_tweet()` è¯„åˆ†ç³»ç»Ÿ
- [ ] æµ‹è¯• `generate_daily_tweets.py` è„šæœ¬
- [ ] æ”¶é›†æœ¬å‘¨ engagement æ•°æ®

### æœ¬æœˆå¯åš:
- [ ] å®ç° A/B æµ‹è¯•æ¡†æ¶
- [ ] æ·»åŠ  engagement è¿½è¸ª
- [ ] è¿è¡Œ `analyze_best_content()` åˆ†æ
- [ ] æ ¹æ®æ•°æ®ä¼˜åŒ– prompt

### é•¿æœŸç›®æ ‡:
- [ ] å»ºç«‹æŒç»­ä¼˜åŒ–å¾ªç¯(æ¯å‘¨)
- [ ] ç§¯ç´¯ >100 æ¡é«˜è´¨é‡ç¤ºä¾‹
- [ ] å®ç°è‡ªåŠ¨åŒ– prompt ä¼˜åŒ–
- [ ] è¾¾åˆ°å¹³å‡ engagement score >50

---

**ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-12-29
**ä¸‹ä¸€æ­¥**: åˆ›å»ºç¤ºä¾‹åº“å¹¶æµ‹è¯•è¯„åˆ†ç³»ç»Ÿ
