"""
æŒç»­å­¦ä¹ ç³»ç»Ÿ
è‡ªåŠ¨åŒ–è®­ç»ƒæ•°æ®æ›´æ–°æµç¨‹
"""

import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict
from ..core.logger import setup_logger
from .content_freshness_monitor import ContentFreshnessMonitor

logger = setup_logger("continuous_learning")


class ContinuousLearningSystem:
    """æŒç»­å­¦ä¹ ç³»ç»Ÿ - ç®¡ç†è®­ç»ƒæ•°æ®æ›´æ–°"""

    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.training_data_dir = self.project_root / "skills"
        self.monitor = ContentFreshnessMonitor()

    def add_training_samples(
        self,
        content_type: str,
        samples: List[Dict],
        source: str = "manual",
        notes: str = "",
    ) -> dict:
        """æ·»åŠ æ–°çš„è®­ç»ƒæ ·æœ¬

        Args:
            content_type: 'gm', 'main', 'casual', etc.
            samples: è®­ç»ƒæ ·æœ¬åˆ—è¡¨ï¼Œæ ¼å¼ï¼š
                [{
                    'text': str,
                    'style': str,
                    'engagement': str,
                    'image': dict (å¯é€‰),
                    ... å…¶ä»–å…ƒæ•°æ®
                }]
            source: æ¥æºï¼ˆ'manual', 'high_engagement_tweets', 'user_feedback'ï¼‰
            notes: å¤‡æ³¨

        Returns:
            {
                'success': bool,
                'added_count': int,
                'total_samples': int,
                'message': str
            }
        """
        try:
            # åŠ è½½ç°æœ‰è®­ç»ƒæ•°æ®
            training_file = (
                self.training_data_dir / f"training_data_{content_type}.json"
            )

            if not training_file.exists():
                return {
                    "success": False,
                    "message": f"Training file not found: {training_file}",
                }

            with open(training_file, "r", encoding="utf-8") as f:
                data = json.load(f)

            # è·å–å½“å‰æœ€å¤§ ID
            existing_samples = data.get("training_samples", [])
            if existing_samples:
                last_id = max(
                    [int(s["id"].split("_")[1]) for s in existing_samples if "id" in s]
                )
            else:
                last_id = 0

            # æ·»åŠ æ–°æ ·æœ¬
            new_samples = []
            for i, sample in enumerate(samples, start=1):
                new_id = f"{content_type}_{str(last_id + i).zfill(3)}"

                new_sample = {
                    "id": new_id,
                    "text": sample["text"],
                    "style": sample.get("style", "unknown"),
                    "emoji_usage": self._detect_emoji(sample["text"]),
                    "length": self._classify_length(sample["text"]),
                    "tone": sample.get("tone", ""),
                    "engagement": sample.get("engagement", "unknown"),
                    "added_date": datetime.now().isoformat(),
                    "source": source,
                }

                # æ·»åŠ å¯é€‰å­—æ®µ
                if "image" in sample:
                    new_sample["image"] = sample["image"]
                if "key_features" in sample:
                    new_sample["key_features"] = sample["key_features"]
                if "emoji_type" in sample:
                    new_sample["emoji_type"] = sample["emoji_type"]

                new_samples.append(new_sample)

            # æ›´æ–°è®­ç»ƒæ•°æ®
            data["training_samples"].extend(new_samples)

            # æ›´æ–°å…ƒæ•°æ®
            if "metadata" not in data:
                data["metadata"] = {}

            data["metadata"]["last_updated"] = datetime.now().isoformat()
            data["metadata"]["total_samples"] = len(data["training_samples"])
            data["metadata"]["latest_addition"] = {
                "date": datetime.now().isoformat(),
                "count": len(new_samples),
                "source": source,
                "notes": notes,
            }

            # ä¿å­˜
            with open(training_file, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            # è®°å½•åˆ°æ–°é²œåº¦ç›‘æ§ç³»ç»Ÿ
            self.monitor.record_training_update(
                training_type=content_type, samples_added=len(new_samples), notes=notes
            )

            logger.info(
                f"Added {len(new_samples)} new samples to {content_type} training data"
            )

            return {
                "success": True,
                "added_count": len(new_samples),
                "total_samples": len(data["training_samples"]),
                "new_ids": [s["id"] for s in new_samples],
                "message": f"Successfully added {len(new_samples)} samples to {content_type}",
            }

        except Exception as e:
            logger.error(f"Error adding training samples: {e}")
            return {"success": False, "message": f"Error: {str(e)}"}

    def _detect_emoji(self, text: str) -> bool:
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å« emoji"""
        import re

        emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map symbols
            "\U0001F1E0-\U0001F1FF"  # flags
            "\U00002700-\U000027BF"  # dingbats
            "\U0001F900-\U0001F9FF"  # supplemental symbols
            "]+",
            flags=re.UNICODE,
        )
        return bool(emoji_pattern.search(text))

    def _classify_length(self, text: str) -> str:
        """åˆ†ç±»æ–‡æœ¬é•¿åº¦"""
        word_count = len(text.split())
        if word_count <= 2:
            return "ultra_minimal"
        elif word_count <= 5:
            return "minimal"
        elif word_count <= 10:
            return "short"
        else:
            return "medium"

    def suggest_training_samples(self, content_type: str = "gm") -> dict:
        """æ ¹æ®å½“å‰çŠ¶æ€å»ºè®®éœ€è¦ä»€ä¹ˆæ ·çš„è®­ç»ƒæ ·æœ¬

        Returns:
            {
                'needs_training': bool,
                'suggestions': list,
                'priority': str
            }
        """
        # æ£€æŸ¥æ–°é²œåº¦
        freshness = self.monitor.check_freshness(content_type)

        suggestions = []
        priority = "LOW"

        if not freshness["is_fresh"]:
            priority = "HIGH"

            # æ ¹æ®é—®é¢˜ç±»å‹ç»™å‡ºå»ºè®®
            for alert in freshness["alerts"]:
                if alert["type"] == "exact_duplicate":
                    suggestions.append(
                        {
                            "type": "new_styles",
                            "description": "éœ€è¦å®Œå…¨ä¸åŒé£æ ¼çš„æ ·æœ¬ï¼ˆæ–°çš„å¥å¼ã€æ–°çš„è¡¨è¾¾æ–¹å¼ï¼‰",
                            "example": 'å¦‚æœç°æœ‰çš„éƒ½æ˜¯ "gm from X"ï¼Œå°è¯•æ·»åŠ  "X says gm" æˆ–é—®é¢˜å¼ "ready for Y?"',
                        }
                    )

                elif alert["type"] == "similar_duplicate":
                    suggestions.append(
                        {
                            "type": "vocabulary_expansion",
                            "description": "éœ€è¦æ‰©å±•è¯æ±‡åº“ï¼ˆæ–°çš„åœ°ç‚¹ã€æ´»åŠ¨ã€å¯¹è±¡ï¼‰",
                            "example": "æ·»åŠ æ–°çš„æŠ€æœ¯æœ¯è¯­ã€æ–°çš„å·¥ä½œåœºæ™¯ã€æ–°çš„æƒ…ç»ªè¡¨è¾¾",
                        }
                    )

                elif alert["type"] == "phrase_reuse":
                    suggestions.append(
                        {
                            "type": "phrase_diversity",
                            "description": f"é«˜é¢‘çŸ­è¯­éœ€è¦æ›¿ä»£: {', '.join(alert['details']['top_phrases'][:3])}",
                            "example": "å¯»æ‰¾åŒä¹‰è¡¨è¾¾ã€æ¢ä¸€ç§è¯´æ³•",
                        }
                    )

                elif alert["type"] == "training_staleness":
                    suggestions.append(
                        {
                            "type": "fresh_content",
                            "description": "éœ€è¦æ¥è‡ªè¿‘æœŸçš„æ–°é²œç´ æ",
                            "example": "æ”¶é›†æœ€è¿‘ 1-2 å‘¨çš„é«˜äº’åŠ¨æ¨æ–‡ã€æ–°å‡ºç°çš„ memeã€æ—¶äº‹çƒ­ç‚¹",
                        }
                    )

        else:
            suggestions.append(
                {
                    "type": "maintenance",
                    "description": "å½“å‰å†…å®¹æ–°é²œåº¦è‰¯å¥½ï¼Œå¯ä»¥ç»§ç»­è§‚å¯Ÿ",
                    "example": "å»ºè®®æ¯ 2-3 å‘¨æ·»åŠ  3-5 ä¸ªæ–°æ ·æœ¬ä¿æŒæ´»åŠ›",
                }
            )

        return {
            "needs_training": not freshness["is_fresh"],
            "priority": priority,
            "freshness_score": freshness.get("freshness_score", 0),
            "suggestions": suggestions,
            "current_stats": freshness["stats"],
        }

    def generate_training_template(
        self, content_type: str = "gm", count: int = 5
    ) -> str:
        """ç”Ÿæˆè®­ç»ƒæ ·æœ¬æ¨¡æ¿ï¼ˆæ–¹ä¾¿ç”¨æˆ·å¡«å†™ï¼‰

        Args:
            content_type: å†…å®¹ç±»å‹
            count: ç”Ÿæˆå‡ ä¸ªæ¨¡æ¿

        Returns:
            JSON æ¨¡æ¿å­—ç¬¦ä¸²
        """
        template = {
            "content_type": content_type,
            "source": "manual / high_engagement_tweets / user_feedback",
            "notes": "æè¿°è¿™æ‰¹æ ·æœ¬çš„æ¥æºå’Œç‰¹ç‚¹",
            "samples": [],
        }

        for i in range(count):
            sample = {
                "text": f"ã€å¡«å†™æ¨æ–‡å†…å®¹ {i+1}ã€‘",
                "style": "ã€å¡«å†™é£æ ¼ï¼Œå¦‚: minimal, meta_humor, call_to_actionã€‘",
                "tone": "ã€å¡«å†™è¯­æ°”ï¼Œå¦‚: casual, encouraging, playfulã€‘",
                "engagement": "ã€å¡«å†™äº’åŠ¨æƒ…å†µï¼Œå¦‚: high (1.2K likes), moderate (200 likes)ã€‘",
                "image": {
                    "has_image": False,
                    "type": "ã€å¦‚æœæœ‰å›¾ï¼Œå¡«å†™: work_scene, meme, product_shot, etc.ã€‘",
                    "description": "ã€å›¾ç‰‡æè¿°ã€‘",
                },
                "key_features": [
                    "ã€è¿™æ¡æ¨æ–‡çš„å…³é”®ç‰¹å¾ 1ã€‘",
                    "ã€è¿™æ¡æ¨æ–‡çš„å…³é”®ç‰¹å¾ 2ã€‘",
                ],
            }
            template["samples"].append(sample)

        return json.dumps(template, ensure_ascii=False, indent=2)

    def import_from_template(self, template_file: str) -> dict:
        """ä»æ¨¡æ¿æ–‡ä»¶å¯¼å…¥è®­ç»ƒæ ·æœ¬

        Args:
            template_file: æ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼ˆJSONï¼‰

        Returns:
            å¯¼å…¥ç»“æœ
        """
        try:
            with open(template_file, "r", encoding="utf-8") as f:
                template = json.load(f)

            content_type = template["content_type"]
            source = template.get("source", "manual")
            notes = template.get("notes", "")
            samples = template["samples"]

            # æ¸…ç†æ¨¡æ¿ä¸­çš„å ä½ç¬¦
            cleaned_samples = []
            for sample in samples:
                # è·³è¿‡æœªå¡«å†™çš„æ¨¡æ¿
                if "ã€å¡«å†™" in sample["text"]:
                    continue
                cleaned_samples.append(sample)

            if not cleaned_samples:
                return {
                    "success": False,
                    "message": "No valid samples found in template (all placeholders)",
                }

            # æ·»åŠ æ ·æœ¬
            result = self.add_training_samples(
                content_type=content_type,
                samples=cleaned_samples,
                source=source,
                notes=notes,
            )

            return result

        except Exception as e:
            logger.error(f"Error importing from template: {e}")
            return {"success": False, "message": f"Error: {str(e)}"}

    def get_learning_dashboard(self) -> str:
        """ç”Ÿæˆå­¦ä¹ çŠ¶æ€ä»ªè¡¨æ¿"""
        lines = ["ğŸ“š æŒç»­å­¦ä¹ ç³»ç»Ÿ - çŠ¶æ€ä»ªè¡¨æ¿", "=" * 70, ""]

        # æ£€æŸ¥å„ç±»å‹å†…å®¹çš„æ–°é²œåº¦
        for content_type in ["gm", "main", "casual"]:
            training_file = (
                self.training_data_dir / f"training_data_{content_type}.json"
            )

            if not training_file.exists():
                continue

            freshness = self.monitor.check_freshness(content_type)
            suggestions = self.suggest_training_samples(content_type)

            status_emoji = "âœ…" if freshness["is_fresh"] else "âš ï¸"
            lines.append(f"{status_emoji} {content_type.upper()} Content")
            lines.append(f"   æ–°é²œåº¦: {freshness.get('freshness_score', 0):.2f} / 1.00")
            lines.append(f"   ä¼˜å…ˆçº§: {suggestions['priority']}")

            if not freshness["is_fresh"]:
                lines.append(f"   é—®é¢˜æ•°: {len(freshness['alerts'])}")
                for alert in freshness["alerts"][:2]:
                    lines.append(f"     - {alert['message']}")

            lines.append("")

        # è®­ç»ƒå†å²
        lines.append("ğŸ“… æœ€è¿‘è®­ç»ƒæ›´æ–°:")
        recent_updates = self.monitor.history["training_data_updates"][-5:]
        if recent_updates:
            for update in recent_updates:
                date = datetime.fromisoformat(update["date"]).strftime("%Y-%m-%d")
                lines.append(
                    f"   {date}: {update['type']} (+{update['samples_added']} æ ·æœ¬)"
                )
        else:
            lines.append("   ï¼ˆæ— è®­ç»ƒè®°å½•ï¼‰")

        lines.append("")
        lines.append("=" * 70)

        return "\n".join(lines)


# ä¾¿æ·å‡½æ•°
def add_training_samples(
    content_type: str, samples: List[Dict], notes: str = ""
) -> dict:
    """å¿«é€Ÿæ·»åŠ è®­ç»ƒæ ·æœ¬"""
    system = ContinuousLearningSystem()
    return system.add_training_samples(content_type, samples, notes=notes)


def get_training_suggestions(content_type: str = "gm") -> dict:
    """è·å–è®­ç»ƒå»ºè®®"""
    system = ContinuousLearningSystem()
    return system.suggest_training_samples(content_type)


def generate_training_template(
    content_type: str = "gm", output_file: str = None
) -> str:
    """ç”Ÿæˆè®­ç»ƒæ¨¡æ¿"""
    system = ContinuousLearningSystem()
    template = system.generate_training_template(content_type)

    if output_file:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(template)
        print(f"âœ… Template saved to: {output_file}")

    return template


# æµ‹è¯•
if __name__ == "__main__":
    system = ContinuousLearningSystem()

    print(system.get_learning_dashboard())
    print("\n")

    # ç”Ÿæˆè®­ç»ƒå»ºè®®
    suggestions = system.suggest_training_samples("gm")
    print(f"éœ€è¦è®­ç»ƒ: {suggestions['needs_training']}")
    print(f"ä¼˜å…ˆçº§: {suggestions['priority']}")
    print(f"æ–°é²œåº¦: {suggestions['freshness_score']:.2f}")
    print("\nå»ºè®®:")
    for s in suggestions["suggestions"]:
        print(f"  - {s['description']}")
        print(f"    ä¾‹å¦‚: {s['example']}")
        print()
